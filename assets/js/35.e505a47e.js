(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{488:function(t,a,s){"use strict";s.r(a);var n=s(14),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"kafka-分区再均衡"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#kafka-分区再均衡"}},[t._v("#")]),t._v(" Kafka 分区再均衡")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#%E4%B8%80%E4%BB%80%E4%B9%88%E6%98%AF-rebalance"}},[t._v("一、什么是 Rebalance")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E4%BA%8Crebalance-%E7%9A%84%E8%A7%A6%E5%8F%91%E6%97%B6%E6%9C%BA"}},[t._v("二、Rebalance 的触发时机")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E4%B8%89rebalance-%E7%9A%84%E8%BF%87%E7%A8%8B"}},[t._v("三、Rebalance 的过程")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#%E6%9F%A5%E6%89%BE%E5%8D%8F%E8%B0%83%E8%80%85"}},[t._v("查找协调者")])])])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E5%9B%9Brebalance-%E7%9A%84%E9%97%AE%E9%A2%98"}},[t._v("四、Rebalance 的问题")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E4%BA%94%E9%81%BF%E5%85%8D-rebalance"}},[t._v("五、避免 Rebalance")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"#%E6%9C%AA%E5%8F%8A%E6%97%B6%E5%8F%91%E9%80%81%E5%BF%83%E8%B7%B3"}},[t._v("未及时发送心跳")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#consumer-%E6%B6%88%E8%B4%B9%E6%97%B6%E9%97%B4%E8%BF%87%E9%95%BF"}},[t._v("Consumer 消费时间过长")])])])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E5%85%AD%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%E7%9A%84%E5%BA%94%E7%94%A8"}},[t._v("六、分区再均衡的应用")])]),t._v(" "),s("li",[s("a",{attrs:{href:"#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"}},[t._v("参考资料")])])]),t._v(" "),s("h2",{attrs:{id:"一、什么是-rebalance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#一、什么是-rebalance"}},[t._v("#")]),t._v(" 一、什么是 Rebalance")]),t._v(" "),s("p",[s("strong",[t._v("分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为分区再均衡（Rebalance）。")])]),t._v(" "),s("p",[s("strong",[t._v("Rebalance 实现了消费者群组的高可用性和伸缩性")]),t._v("。")]),t._v(" "),s("p",[s("strong",[t._v("消费者通过向被指派为群组协调器（Coordinator）的 broker 发送心跳来维持它们和群组的从属关系以及它们对分区的所有权")]),t._v("。")]),t._v(" "),s("p",[t._v("所谓协调者，在 Kafka 中对应的术语是 Coordinator，它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。具体来讲，Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。")]),t._v(" "),s("p",[t._v("当在群组里面 新增/移除消费者 或者 新增/移除 kafka 集群 broker 节点 时，群组协调器 Broker 会触发再均衡，重新为每一个 Partition 分配消费者。"),s("strong",[t._v("Rebalance 期间，消费者无法读取消息，造成整个消费者群组一小段时间的不可用。")])]),t._v(" "),s("p",[s("strong",[t._v("Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区")]),t._v("。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance。")]),t._v(" "),s("h2",{attrs:{id:"二、rebalance-的触发时机"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#二、rebalance-的触发时机"}},[t._v("#")]),t._v(" 二、Rebalance 的触发时机")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("组成员数发生变更")]),t._v("。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。\n"),s("ul",[s("li",[t._v("新增消费者。customer 订阅主题之后，第一次执行 poll 方法")]),t._v(" "),s("li",[t._v("移除消费者。执行 customer.close()操作或者消费客户端宕机，就不再通过 poll 向群组协调器发送心跳了，当群组协调器检测次消费者没有心跳，就会触发再均衡。")])])]),t._v(" "),s("li",[s("strong",[t._v("订阅主题数发生变更")]),t._v("。Consumer Group 可以使用正则表达式的方式订阅主题，比如 "),s("code",[t._v("consumer.subscribe(Pattern.compile(“t.*c”))")]),t._v(" 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance。")]),t._v(" "),s("li",[s("strong",[t._v("订阅主题的分区数发生变更")]),t._v("。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。\n"),s("ul",[s("li",[t._v("新增 broker。如重启 broker 节点")]),t._v(" "),s("li",[t._v("移除 broker。如 kill 掉 broker 节点。")])])])]),t._v(" "),s("h2",{attrs:{id:"三、rebalance-的过程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#三、rebalance-的过程"}},[t._v("#")]),t._v(" 三、Rebalance 的过程")]),t._v(" "),s("p",[s("strong",[t._v("Rebalance 是通过消费者群组中的称为“群主”消费者客户端进行的")]),t._v("。什么是群主呢？“群主”就是第一个加入群组的消费者。消费者第一次加入群组时，它会向群组协调器发送一个 JoinGroup 的请求，如果是第一个，则此消费者被指定为“群主”（群主是不是和 qq 群很想啊，就是那个第一个进群的人）。")]),t._v(" "),s("p",[s("img",{attrs:{src:"http://dunwu.test.upcdn.net/snap/20200727153700.png",alt:"img"}})]),t._v(" "),s("ol",[s("li",[t._v("群主从群组协调器获取群组成员列表，然后给每一个消费者进行分配分区 Partition。有两种分配策略：Range 和 RoundRobin。\n"),s("ul",[s("li",[s("strong",[t._v("Range 策略")]),t._v("，就是把若干个连续的分区分配给消费者，如存在分区 1-5，假设有 3 个消费者，则消费者 1 负责分区 1-2,消费者 2 负责分区 3-4，消费者 3 负责分区 5。")]),t._v(" "),s("li",[s("strong",[t._v("RoundRoin 策略")]),t._v("，就是把所有分区逐个分给消费者，如存在分区 1-5，假设有 3 个消费者，则分区 1->消费 1，分区 2->消费者 2，分区 3>消费者 3，分区 4>消费者 1，分区 5->消费者 2。")])])]),t._v(" "),s("li",[t._v("群主分配完成之后，把分配情况发送给群组协调器。")]),t._v(" "),s("li",[t._v("群组协调器再把这些信息发送给消费者。"),s("strong",[t._v("每一个消费者只能看到自己的分配信息，只有群主知道所有消费者的分配信息")]),t._v("。")])]),t._v(" "),s("h3",{attrs:{id:"查找协调者"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#查找协调者"}},[t._v("#")]),t._v(" 查找协调者")]),t._v(" "),s("p",[t._v("所有 Broker 在启动时，都会创建和开启相应的 Coordinator 组件。也就是说，"),s("strong",[t._v("所有 Broker 都有各自的 Coordinator 组件")]),t._v("。那么，Consumer Group 如何确定为它服务的 Coordinator 在哪台 Broker 上呢？答案就在我们之前说过的 Kafka 内部位移主题 "),s("code",[t._v("__consumer_offsets")]),t._v(" 身上。")]),t._v(" "),s("p",[t._v("目前，Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤。")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("第 1 步：确定由位移主题的哪个分区来保存该 Group 数据："),s("code",[t._v("partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)")]),t._v("。")])]),t._v(" "),s("li",[s("p",[t._v("第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。")])])]),t._v(" "),s("h2",{attrs:{id:"四、rebalance-的问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#四、rebalance-的问题"}},[t._v("#")]),t._v(" 四、Rebalance 的问题")]),t._v(" "),s("ul",[s("li",[t._v("首先，"),s("strong",[t._v("在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成")]),t._v("。")]),t._v(" "),s("li",[t._v("其次，"),s("strong",[t._v("目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区")]),t._v("。其实更高效的做法是尽量减少分配方案的变动。例如实例 A 之前负责消费分区 1、2、3，那么 Rebalance 之后，如果可能的话，最好还是让实例 A 继续消费分区 1、2、3，而不是被重新分配其他的分区。这样的话，实例 A 连接这些分区所在 Broker 的 TCP 连接就可以继续用，不用重新创建连接其他 Broker 的 Socket 资源。")]),t._v(" "),s("li",[t._v("最后，"),s("strong",[t._v("Rebalance 实在太慢了")]),t._v("。曾经，有个国外用户的 Group 内有几百个 Consumer 实例，成功 Rebalance 一次要几个小时！这完全是不能忍受的。最悲剧的是，目前社区对此无能为力，至少现在还没有特别好的解决方案。所谓“本事大不如不摊上”，也许最好的解决方案就是避免 Rebalance 的发生吧。")])]),t._v(" "),s("p",[t._v("Rebalance 整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。")]),t._v(" "),s("h2",{attrs:{id:"五、避免-rebalance"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#五、避免-rebalance"}},[t._v("#")]),t._v(" 五、避免 Rebalance")]),t._v(" "),s("p",[t._v("了解了 Rebalance 的问题，我们可以知道，如果减少 Rebalance，可以整体提高 Consumer 的 TPS。")]),t._v(" "),s("p",[t._v("前面介绍了，Rebalance 的触发时机有三个。其中，增加 Consumer 实例的操作都是计划内的，可能是出于增加 TPS 或提高伸缩性的需要。")]),t._v(" "),s("h3",{attrs:{id:"未及时发送心跳"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#未及时发送心跳"}},[t._v("#")]),t._v(" 未及时发送心跳")]),t._v(" "),s("p",[s("strong",[t._v("第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被“踢出”Group 而引发的")]),t._v("。因此，你需要仔细地设置 **"),s("code",[t._v("session.timeout.ms")]),t._v(" 和 "),s("code",[t._v("heartbeat.interval.ms")]),t._v("**的值。我在这里给出一些推荐数值，你可以“无脑”地应用在你的生产环境中。")]),t._v(" "),s("ul",[s("li",[t._v("设置 "),s("code",[t._v("session.timeout.ms")]),t._v(" = 6s。")]),t._v(" "),s("li",[t._v("设置 "),s("code",[t._v("heartbeat.interval.ms")]),t._v(" = 2s。")]),t._v(" "),s("li",[t._v("要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 "),s("code",[t._v("session.timeout.ms >= 3 * heartbeat.interval.ms")]),t._v("。")])]),t._v(" "),s("p",[t._v("将 "),s("code",[t._v("session.timeout.ms")]),t._v(" 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer。毕竟，我们还是希望能尽快揪出那些“尸位素餐”的 Consumer，早日把它们踢出 Group。希望这份配置能够较好地帮助你规避第一类“不必要”的 Rebalance。")]),t._v(" "),s("h3",{attrs:{id:"consumer-消费时间过长"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#consumer-消费时间过长"}},[t._v("#")]),t._v(" Consumer 消费时间过长")]),t._v(" "),s("p",[s("strong",[t._v("第二类非必要 Rebalance 是 Consumer 消费时间过长导致的")]),t._v("。我之前有一个客户，在他们的场景中，Consumer 消费数据时需要将消息处理之后写入到 MongoDB。显然，这是一个很重的消费逻辑。MongoDB 的一丁点不稳定都会导致 Consumer 程序消费时长的增加。此时，"),s("strong",[s("code",[t._v("max.poll.interval.ms")])]),t._v(" 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。就拿 MongoDB 这个例子来说，如果写 MongoDB 的最长时间是 7 分钟，那么你可以将该参数设置为 8 分钟左右。")]),t._v(" "),s("p",[t._v("如果你按照上面的推荐数值恰当地设置了这几个参数，却发现还是出现了 Rebalance，那么我建议你去排查一下"),s("strong",[t._v("Consumer 端的 GC 表现")]),t._v("，比如是否出现了频繁的 Full GC 导致的长时间停顿，从而引发了 Rebalance。为什么特意说 GC？那是因为在实际场景中，我见过太多因为 GC 设置不合理导致程序频发 Full GC 而引发的非预期 Rebalance 了。")]),t._v(" "),s("h2",{attrs:{id:"六、分区再均衡的应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#六、分区再均衡的应用"}},[t._v("#")]),t._v(" 六、分区再均衡的应用")]),t._v(" "),s("p",[t._v("如果 Kafka 触发了再均衡，我们需要在消费者失去对一个分区的所有权之前提交最后一个已处理记录的偏移量。如果消费者准备了一个缓冲区用于处理偶发的事件，那么在失去分区所有权之前，需要处理在缓冲区累积下来的记录。可能还需要关闭文件句柄、数据库连接等。")]),t._v(" "),s("p",[t._v("在为消费者分配新分区或移除旧分区时，可以通过消费者 API 执行一些应用程序代码，在调用 "),s("code",[t._v("subscribe()")]),t._v(" 方法时传进去一个 "),s("code",[t._v("ConsumerRebalanceListener")]),t._v(" 实例就可以了。 "),s("code",[t._v("ConsumerRebalanceListener")]),t._v(" 有两个需要实现的方法。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("public void onPartitionsRevoked(Collection partitions)")]),t._v(" 方法会在再均衡开始之前和消费者停止读取消息之后被调用。如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取了。")]),t._v(" "),s("li",[s("code",[t._v("public void onPartitionsAssigned(Collection partitions)")]),t._v(" 方法会在重新分配分区之后和消费者开始读取消息之前被调用。")])]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TopicPartition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("OffsetAndMetadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" currentOffsets"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HandleRebalance")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConsumerRebalanceListener")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("onPartitionsAssigned")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collection")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TopicPartition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n      partitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("onPartitionsRevoked")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collection")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TopicPartition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n      partitions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v('"'),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Lost")]),t._v(" partitions in rebalance"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Committing")]),t._v(" current\n        offsets"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v('" '),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" currentOffsets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitSync")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentOffsets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("subscribe")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topics"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HandleRebalance")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConsumerRecords")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" records "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n          consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("poll")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ConsumerRecord")]),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" records"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v('"topic '),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" partition "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             customer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" country "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v('s\\n"'),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("topic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("offset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("key")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n             currentOffsets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TopicPartition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("topic")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("partition")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v("\n             "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("OffsetAndMetadata")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("offset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"no metadata"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitAsync")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentOffsets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("WakeupException")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 忽略异常，正在关闭消费者")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    log"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("error")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Unexpected error"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("commitSync")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentOffsets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        consumer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Closed consumer and we are done"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h2",{attrs:{id:"参考资料"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("官方")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"http://kafka.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kakfa 官网"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://github.com/apache/kafka",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kakfa Github"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://kafka.apache.org/documentation/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kakfa 官方文档"),s("OutboundLink")],1)])])]),t._v(" "),s("li",[s("strong",[t._v("书籍")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://item.jd.com/12270295.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("《Kafka 权威指南》"),s("OutboundLink")],1)])])]),t._v(" "),s("li",[s("strong",[t._v("教程")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://github.com/apachecn/kafka-doc-zh",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka 中文文档"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://time.geekbang.org/column/intro/100029201",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka 核心技术与实战"),s("OutboundLink")],1)])])]),t._v(" "),s("li",[s("strong",[t._v("文章")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://www.infoq.cn/article/kafka-analysis-part-7",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kafka 设计解析（七）：流式计算的新贵 Kafka Stream"),s("OutboundLink")],1)])])])])])}),[],!1,null,null,null);a.default=e.exports}}]);